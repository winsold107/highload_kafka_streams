## День 1

**00:00-01:00** презентация

  - Что такое лог и почему это важно
  - Что такое Kafka и что она умеет
    - Устройство кафка-кластера
    - Топики, партиции и репликация
    - Запись в Kafka
    - Чтение из Kafka
    - Retention
    - Компактификация топиков
  - Что такое потоковая архитектура и на что способны потоковые обработчики
    - Компоненты потоковой архитектуры
    - Фреймворки потоковой обработки данных
    - Задачи, которые способна решать потоковая архитектура
    - Особенности эксплуатации и развития потоковых систем
    - Границы применимости потоковых систем
  - Основные инструменты разработчика
    - Как запустить Kafka локально
    - kafkacat
    - Conduktor 

**01:00-01:15** Перерыв 

**01:15-02:00** hands-on practice 1: 

* запустить Kafka-кластер локально (docker-compose up), 
  * создать топик в Conduktor с тремя партициями
  * записать туда данные с разными ключами и значениями
  * подписаться на топик через kafkacat
  * пронаблюдать нарушение порядка между партициями и сохранение порядка внутри партиции

* запись/чтение данных в kafkacat в реальном времени без consumer group
  * что при перезапуске kafkacat? 
  * что при параллельном запуске kafkacat?

* запись/чтение данных в kafkacat в реальном времени c consumer group
  * что при перезапуске kafkacat? 
  * что при параллельном запуске kafkacat?

**02:00-02:15** перерыв

**02:15-02:45** презентация

* Kafka Streams: основы и stateless трансформации
* Конфигурация приложения. 
  * Топология: создание, визуализация
  * `TopologyTestDriver`
  * Жизненный цикл KStreams-приложения и обработка исключений
  * Простые (stateless) трансформации 

**02:45-03:15** hands-on practice 2: 

* создать потоковое приложение, использующее stateless трансформацию, 
* визуализировать топологию,
* создать unit-test, 
* протестировать падение приложения при вводе некорректных данных и обработку ошибок.

**03:15-03:30** перерыв

**03:30-04:00** презентация

* Трансформации с использованием локального состояния
  * RocksDB и его использование в KStreams
  * Использование KVStore
  * Ребалансировка, сохранение и восстановление KVStore в служебных топиках
  * Репартиционирование явное и неявное, способы уменьшения числа репартиционирований

## День 2

**00:00-00:30** hands-on practice 

* Создание приложения, использующего локальный KVStore. 
* Эксперимент с запуском нескольких копий приложения, демонстрирующий работу ребалансировки и автоматической репликации KVStore между обработчиками. 
* Исследование и интерпретация содержимого служебных топиков

**00:30-01:00** презентация  

* Дуализм «поток—таблица» и табличные join-ы
  * Таблицы vs стримы
  * join таблица-таблица
  * Копартиционирование
  * Глобальные таблицы
  
**01:00-01:15** перерыв
 
**01:15-01:45** hands-on practice 

* Переписывание предыдущего примера с использованием `aggregate`
* развитие предыдущего примера: использование табличных join-ов
* left join

**01:45-02:15** презентация

* Время и оконные операции
  * Общая карта KStreams API
  * Зачем нужны "окна"?: stream-table и stream-stream join-ы
  * Как устроены окна с точки зрения хранения в RocksDB
  * Откуда берётся время: `TimestampExtractor`

**02:15-02:30** перерыв

**02:30-03:00** hands-on practice 
 
* реализация stream-stream join. 
* Модульный тест. 
* Явное указание штампов времени без использования sleep-ов при тестировании.

**03:00-03:30** презентация

* Какие ещё бывают окна: Tumbling, Hopping, Session
* Window retention time
* Punctuator

**03:30-04:00** 
* hands-on practice (если останется время): агрегация сообщений в tumbling window.
* Завершение. Источники знаний о Kafka: книги, доклады и сообщества
* Ответы на вопросы
